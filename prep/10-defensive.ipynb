{"nbformat_minor": 0, "metadata": {}, "cells": [{"attachments": {}, "cell_type": "markdown", "source": "---  \n# Defensive Programming  \nteaching: 30  \nexercises: 10  \nquestions:  \n- \"How can I make my programs more reliable?\"  \nobjectives:  \n- \"Explain what an assertion is.\"  \n- \"Add assertions that check the program's state is correct.\"  \n- \"Correctly add precondition and postcondition assertions to functions.\"  \n- \"Explain what test-driven development is, and use it when creating new functions.\"  \n- \"Explain why variables should be initialized using actual data values  \n   rather than arbitrary constants.\"  \nkeypoints:  \n- \"Program defensively, i.e., assume that errors are going to arise,  \n   and write code to detect them when they do.\"  \n- \"Put assertions in programs to check their state as they run,  \n   and to help readers understand how those programs are supposed to work.\"  \n- \"Use preconditions to check that the inputs to a function are safe to use.\"  \n- \"Use postconditions to check that the output from a function is safe to use.\"  \n- \"Write tests before writing code in order to help determine exactly  \n   what that code is supposed to do.\"  \n---  \n\nOur previous lessons have introduced the basic tools of programming:  \nvariables and lists,  \nfile I/O,  \nloops,  \nconditionals,  \nand functions.  \nWhat they *haven't* done is show us how to tell  \nwhether a program is getting the right answer,  \nand how to tell if it's *still* getting the right answer  \nas we make changes to it.  \n\nTo achieve that,  \nwe need to:  \n\n*   Write programs that check their own operation.  \n*   Write and run tests for widely-used functions.  \n*   Make sure we know what \"correct\" actually means.  \n\nThe good news is,  \ndoing these things will speed up our programming,  \nnot slow it down.  \nAs in real carpentry --- the kind done with lumber --- the time saved  \nby measuring carefully before cutting a piece of wood  \nis much greater than the time that measuring takes.  \n\n## Assertions  \n\nThe first step toward getting the right answers from our programs  \nis to assume that mistakes *will* happen  \nand to guard against them.  \nThis is called <span style=\"color:red\" title=\"The practice of writing programs that check their own operation  \nto catch errors as early as possible.\">defensive programming</span>  \nand the most common way to do it is to add  \n<span style=\"color:red\" title=\"An expression which is supposed to be true at a particular point in a program.  \nProgrammers typically put assertions in their code to check for errors;  \nif the assertion fails (i.e., if the expression evaluates as false),  \nthe program halts and produces an error message.  \nSee also: invariant, precondition,  \npostcondition.\">assertions</span>  \nso that it checks itself as it runs.  \nAn assertion is simply a statement that something must be true at a certain point in a program.  \nWhen Python sees one,  \nit evaluates the assertion's condition.  \nIf it's true,  \nPython does nothing,  \nbut if it's false,  \nPython halts the program immediately  \nand prints the error message if one is provided.  \nFor example,  \nthis piece of code halts as soon as the loop encounters a value that isn't positive:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "numbers = [1.5, 2.3, 0.7, -0.001, 4.4]\ntotal = 0.0\nfor num in numbers:\n    assert num > 0.0, 'Data should only contain positive values'\n    total += num\nprint('total is:', total)", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-19-33d87ea29ae4> in <module>()  \n      2 total = 0.0  \n      3 for num in numbers:  \n----> 4     assert num > 0.0, 'Data should only contain positive values'  \n      5     total += num  \n      6 print('total is:', total)  \n\nAssertionError: Data should only contain positive values  \n```\n---  \n{: .error}  \n\nPrograms like the Firefox browser are full of assertions:  \n10-20% of the code they contain  \nare there to check that the other 80\u201390% are working correctly.  \nBroadly speaking,  \nassertions fall into three categories:  \n\n*   A <span style=\"color:red\" title=\"A condition that must be true in order for a function (or other block of code)  \nto run correctly.\">precondition</span>  \n    is something that must be true at the start of a function in order for it to work correctly.  \n\n*   A <span style=\"color:red\" title=\"A condition that a function (or other block of code) guarantees is true  \nonce it has finished running.  \nPostconditions are often represented using assertions.\">postcondition</span>  \n    is something that the function guarantees is true when it finishes.  \n\n*   An <span style=\"color:red\" title=\"An expression whose value doesn't change during the execution of a program,  \ntypically used in an assertion.  \nSee also: precondition, postcondition.\">invariant</span>  \n    is something that is always true at a particular point inside a piece of code.  \n\nFor example,  \nsuppose we are representing rectangles using a <span style=\"color:red\" title=\"An immutable sequence of values.\">tuple</span>  \nof four coordinates `(x0, y0, x1, y1)`,  \nrepresenting the lower left and upper right corners of the rectangle.  \nIn order to do some calculations,  \nwe need to normalize the rectangle so that the lower left corner is at the origin  \nand the longest side is 1.0 units long.  \nThis function does that,  \nbut checks that its input is correctly formatted and that its result makes sense:  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "Programs like the Firefox browser are full of assertions:  \n10-20% of the code they contain  \nare there to check that the other 80\u201390% are working correctly.  \nBroadly speaking,  \nassertions fall into three categories:  \n\n*   A <span style=\"color:red\" title=\"A condition that must be true in order for a function (or other block of code)  \nto run correctly.\">precondition</span>  \n    is something that must be true at the start of a function in order for it to work correctly.  \n\n*   A <span style=\"color:red\" title=\"A condition that a function (or other block of code) guarantees is true  \nonce it has finished running.  \nPostconditions are often represented using assertions.\">postcondition</span>  \n    is something that the function guarantees is true when it finishes.  \n\n*   An <span style=\"color:red\" title=\"An expression whose value doesn't change during the execution of a program,  \ntypically used in an assertion.  \nSee also: precondition, postcondition.\">invariant</span>  \n    is something that is always true at a particular point inside a piece of code.  \n\nFor example,  \nsuppose we are representing rectangles using a <span style=\"color:red\" title=\"An immutable sequence of values.\">tuple</span>  \nof four coordinates `(x0, y0, x1, y1)`,  \nrepresenting the lower left and upper right corners of the rectangle.  \nIn order to do some calculations,  \nwe need to normalize the rectangle so that the lower left corner is at the origin  \nand the longest side is 1.0 units long.  \nThis function does that,  \nbut checks that its input is correctly formatted and that its result makes sense:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "def normalize_rectangle(rect):\n    \"\"\"Normalizes a rectangle so that it is at the origin and 1.0 units long on its longest axis.\n    Input should be of the format (x0, y0, x1, y1).\n    (x0, y0) and (x1, y1) define the lower left and upper right corners\n    of the rectangle, respectively.\"\"\"\n    assert len(rect) == 4, 'Rectangles must contain 4 coordinates'\n    x0, y0, x1, y1 = rect\n    assert x0 < x1, 'Invalid X coordinates'\n    assert y0 < y1, 'Invalid Y coordinates'\n\n    dx = x1 - x0\n    dy = y1 - y0\n    if dx > dy:\n        scaled = float(dx) / dy\n        upper_x, upper_y = 1.0, scaled\n    else:\n        scaled = float(dx) / dy\n        upper_x, upper_y = scaled, 1.0\n\n    assert 0 < upper_x <= 1.0, 'Calculated upper X coordinate invalid'\n    assert 0 < upper_y <= 1.0, 'Calculated upper Y coordinate invalid'\n\n    return (0, 0, upper_x, upper_y)", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "The preconditions on lines 6, 8, and 9 catch invalid inputs:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "print(normalize_rectangle( (0.0, 1.0, 2.0) )) # missing the fourth coordinate", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-2-1b9cd8e18a1f> in <module>  \n----> 1 print(normalize_rectangle( (0.0, 1.0, 2.0) )) # missing the fourth coordinate  \n\n<ipython-input-1-c94cf5b065b9> in normalize_rectangle(rect)  \n      4     (x0, y0) and (x1, y1) define the lower left and upper right corners  \n      5     of the rectangle, respectively.\"\"\"  \n----> 6     assert len(rect) == 4, 'Rectangles must contain 4 coordinates'  \n      7     x0, y0, x1, y1 = rect  \n      8     assert x0 < x1, 'Invalid X coordinates'  \n\nAssertionError: Rectangles must contain 4 coordinates  \n```\n---  \n{: .error}  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "print(normalize_rectangle( (4.0, 2.0, 1.0, 5.0) )) # X axis inverted", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-3-325036405532> in <module>  \n----> 1 print(normalize_rectangle( (4.0, 2.0, 1.0, 5.0) )) # X axis inverted  \n\n<ipython-input-1-c94cf5b065b9> in normalize_rectangle(rect)  \n      6     assert len(rect) == 4, 'Rectangles must contain 4 coordinates'  \n      7     x0, y0, x1, y1 = rect  \n----> 8     assert x0 < x1, 'Invalid X coordinates'  \n      9     assert y0 < y1, 'Invalid Y coordinates'  \n     10  \n\nAssertionError: Invalid X coordinates  \n```\n---  \n{: .error}  \n\nThe post-conditions on lines 20 and 21 help us catch bugs by telling us when our  \ncalculations might have been incorrect.  \nFor example,  \nif we normalize a rectangle that is taller than it is wide everything seems OK:  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "The post-conditions on lines 20 and 21 help us catch bugs by telling us when our  \ncalculations might have been incorrect.  \nFor example,  \nif we normalize a rectangle that is taller than it is wide everything seems OK:  \n", "metadata": {}}, {"outputs": [{"metadata": {}, "execution_count": 1, "data": {"text/plain": ["(0, 0, 0.2, 1.0)"]}, "output_type": "execute_result"}], "cell_type": "code", "source": "print(normalize_rectangle( (0.0, 0.0, 1.0, 5.0) ))", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "but if we normalize one that's wider than it is tall,  \nthe assertion is triggered:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "print(normalize_rectangle( (0.0, 0.0, 5.0, 1.0) ))", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {"fig/python-overlapping-ranges.svg": {"image/svg+xml": "UTF-8"}}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-5-8d4a48f1d068> in <module>  \n----> 1 print(normalize_rectangle( (0.0, 0.0, 5.0, 1.0) ))  \n\n<ipython-input-1-c94cf5b065b9> in normalize_rectangle(rect)  \n     19  \n     20     assert 0 < upper_x <= 1.0, 'Calculated upper X coordinate invalid'  \n---> 21     assert 0 < upper_y <= 1.0, 'Calculated upper Y coordinate invalid'  \n     22  \n     23     return (0, 0, upper_x, upper_y)  \n\nAssertionError: Calculated upper Y coordinate invalid  \n```\n---  \n{: .error}  \n\nRe-reading our function,  \nwe realize that line 14 should divide `dy` by `dx` rather than `dx` by `dy`.  \nIn a Jupyter notebook, you can display line numbers by typing <kbd>Ctrl</kbd>+<kbd>M</kbd>  \nfollowed by <kbd>L</kbd>.  \nIf we had left out the assertion at the end of the function,  \nwe would have created and returned something that had the right shape as a valid answer,  \nbut wasn't.  \nDetecting and debugging that would almost certainly have taken more time in the long run  \nthan writing the assertion.  \n\nBut assertions aren't just about catching errors:  \nthey also help people understand programs.  \nEach assertion gives the person reading the program  \na chance to check (consciously or otherwise)  \nthat their understanding matches what the code is doing.  \n\nMost good programmers follow two rules when adding assertions to their code.  \nThe first is, *fail early, fail often*.  \nThe greater the distance between when and where an error occurs and when it's noticed,  \nthe harder the error will be to debug,  \nso good code catches mistakes as early as possible.  \n\nThe second rule is, *turn bugs into assertions or tests*.  \nWhenever you fix a bug, write an assertion that catches the mistake  \nshould you make it again.  \nIf you made a mistake in a piece of code,  \nthe odds are good that you have made other mistakes nearby,  \nor will make the same mistake (or a related one)  \nthe next time you change it.  \nWriting assertions to check that you haven't <span style=\"color:red\" title=\"To re-introduce a bug that was once fixed.\">regressed</span>  \n(i.e., haven't re-introduced an old problem)  \ncan save a lot of time in the long run,  \nand helps to warn people who are reading the code  \n(including your future self)  \nthat this bit is tricky.  \n\n## Test-Driven Development  \n\nAn assertion checks that something is true at a particular point in the program.  \nThe next step is to check the overall behavior of a piece of code,  \ni.e.,  \nto make sure that it produces the right output when it's given a particular input.  \nFor example,  \nsuppose we need to find where two or more time series overlap.  \nThe range of each time series is represented as a pair of numbers,  \nwhich are the time the interval started and ended.  \nThe output is the largest range that they all include:  \n\n> <img src=fig/python-overlapping-ranges.svg>Overlapping Ranges  \n\nMost novice programmers would solve this problem like this:  \n\n1.  Write a function `range_overlap`.  \n2.  Call it interactively on two or three different inputs.  \n3.  If it produces the wrong answer, fix the function and re-run that test.  \n\nThis clearly works --- after all, thousands of scientists are doing it right now --- but  \nthere's a better way:  \n\n1.  Write a short function for each test.  \n2.  Write a `range_overlap` function that should pass those tests.  \n3.  If `range_overlap` produces any wrong answers, fix it and re-run the test functions.  \n\nWriting the tests *before* writing the function they exercise  \nis called <span style=\"color:red\" title=\"\">test-driven development</span>  \nIts advocates believe it produces better code faster because:  \n\n1.  If people write tests after writing the thing to be tested,  \n    they are subject to confirmation bias,  \n    i.e.,  \n    they subconsciously write tests to show that their code is correct,  \n    rather than to find errors.  \n2.  Writing tests helps programmers figure out what the function is actually supposed to do.  \n\nHere are three test functions for `range_overlap`:  \n", "metadata": {}}, {"attachments": {"fig/python-overlapping-ranges.svg": {"image/svg+xml": "UTF-8"}}, "cell_type": "markdown", "source": "Re-reading our function,  \nwe realize that line 14 should divide `dy` by `dx` rather than `dx` by `dy`.  \nIn a Jupyter notebook, you can display line numbers by typing <kbd>Ctrl</kbd>+<kbd>M</kbd>  \nfollowed by <kbd>L</kbd>.  \nIf we had left out the assertion at the end of the function,  \nwe would have created and returned something that had the right shape as a valid answer,  \nbut wasn't.  \nDetecting and debugging that would almost certainly have taken more time in the long run  \nthan writing the assertion.  \n\nBut assertions aren't just about catching errors:  \nthey also help people understand programs.  \nEach assertion gives the person reading the program  \na chance to check (consciously or otherwise)  \nthat their understanding matches what the code is doing.  \n\nMost good programmers follow two rules when adding assertions to their code.  \nThe first is, *fail early, fail often*.  \nThe greater the distance between when and where an error occurs and when it's noticed,  \nthe harder the error will be to debug,  \nso good code catches mistakes as early as possible.  \n\nThe second rule is, *turn bugs into assertions or tests*.  \nWhenever you fix a bug, write an assertion that catches the mistake  \nshould you make it again.  \nIf you made a mistake in a piece of code,  \nthe odds are good that you have made other mistakes nearby,  \nor will make the same mistake (or a related one)  \nthe next time you change it.  \nWriting assertions to check that you haven't <span style=\"color:red\" title=\"To re-introduce a bug that was once fixed.\">regressed</span>  \n(i.e., haven't re-introduced an old problem)  \ncan save a lot of time in the long run,  \nand helps to warn people who are reading the code  \n(including your future self)  \nthat this bit is tricky.  \n\n## Test-Driven Development  \n\nAn assertion checks that something is true at a particular point in the program.  \nThe next step is to check the overall behavior of a piece of code,  \ni.e.,  \nto make sure that it produces the right output when it's given a particular input.  \nFor example,  \nsuppose we need to find where two or more time series overlap.  \nThe range of each time series is represented as a pair of numbers,  \nwhich are the time the interval started and ended.  \nThe output is the largest range that they all include:  \n\n> <img src=fig/python-overlapping-ranges.svg>Overlapping Ranges  \n\nMost novice programmers would solve this problem like this:  \n\n1.  Write a function `range_overlap`.  \n2.  Call it interactively on two or three different inputs.  \n3.  If it produces the wrong answer, fix the function and re-run that test.  \n\nThis clearly works --- after all, thousands of scientists are doing it right now --- but  \nthere's a better way:  \n\n1.  Write a short function for each test.  \n2.  Write a `range_overlap` function that should pass those tests.  \n3.  If `range_overlap` produces any wrong answers, fix it and re-run the test functions.  \n\nWriting the tests *before* writing the function they exercise  \nis called <span style=\"color:red\" title=\"\">test-driven development</span>  \nIts advocates believe it produces better code faster because:  \n\n1.  If people write tests after writing the thing to be tested,  \n    they are subject to confirmation bias,  \n    i.e.,  \n    they subconsciously write tests to show that their code is correct,  \n    rather than to find errors.  \n2.  Writing tests helps programmers figure out what the function is actually supposed to do.  \n\nHere are three test functions for `range_overlap`:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)\nassert range_overlap([ (2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)\nassert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-25-d8be150fbef6> in <module>()  \n----> 1 assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)  \n      2 assert range_overlap([ (2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)  \n      3 assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)  \n\nAssertionError:  \n```\n---  \n{: .error}  \n\nThe error is actually reassuring:  \nwe haven't written `range_overlap` yet,  \nso if the tests passed,  \nit would be a sign that someone else had  \nand that we were accidentally using their function.  \n\nAnd as a bonus of writing these tests,  \nwe've implicitly defined what our input and output look like:  \nwe expect a list of pairs as input,  \nand produce a single pair as output.  \n\nSomething important is missing, though.  \nWe don't have any tests for the case where the ranges don't overlap at all:  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "The error is actually reassuring:  \nwe haven't written `range_overlap` yet,  \nso if the tests passed,  \nit would be a sign that someone else had  \nand that we were accidentally using their function.  \n\nAnd as a bonus of writing these tests,  \nwe've implicitly defined what our input and output look like:  \nwe expect a list of pairs as input,  \nand produce a single pair as output.  \n\nSomething important is missing, though.  \nWe don't have any tests for the case where the ranges don't overlap at all:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == ???", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "What should `range_overlap` do in this case:  \nfail with an error message,  \nproduce a special value like `(0.0, 0.0)` to signal that there's no overlap,  \nor something else?  \nAny actual implementation of the function will do one of these things;  \nwriting the tests first helps us figure out which is best  \n*before* we're emotionally invested in whatever we happened to write  \nbefore we realized there was an issue.  \n\nAnd what about this case?  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == ???", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "Do two segments that touch at their endpoints overlap or not?  \nMathematicians usually say \"yes\",  \nbut engineers usually say \"no\".  \nThe best answer is \"whatever is most useful in the rest of our program\",  \nbut again,  \nany actual implementation of `range_overlap` is going to do *something*,  \nand whatever it is ought to be consistent with what it does when there's no overlap at all.  \n\nSince we're planning to use the range this function returns  \nas the X axis in a time series chart,  \nwe decide that:  \n\n1.  every overlap has to have non-zero width, and  \n2.  we will return the special value `None` when there's no overlap.  \n\n`None` is built into Python,  \nand means \"nothing here\".  \n(Other languages often call the equivalent value `null` or `nil`).  \nWith that decision made,  \nwe can finish writing our last two tests:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None\nassert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-26-d877ef460ba2> in <module>()  \n----> 1 assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None  \n      2 assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None  \n\nAssertionError:  \n```\n---  \n{: .error}  \n\nAgain,  \nwe get an error because we haven't written our function,  \nbut we're now ready to do so:  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "Again,  \nwe get an error because we haven't written our function,  \nbut we're now ready to do so:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "def range_overlap(ranges):\n    \"\"\"Return common overlap among a set of [left, right] ranges.\"\"\"\n    max_left = 0.0\n    min_right = 1.0\n    for (left, right) in ranges:\n        max_left = max(max_left, left)\n        min_right = min(min_right, right)\n    return (max_left, min_right)", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "Take a moment to think about why we calculate the left endpoint of the overlap as  \nthe maximum of the input left endpoints, and the overlap right endpoint as the minimum  \nof the input right endpoints.  \nWe'd now like to re-run our tests,  \nbut they're scattered across three different cells.  \nTo make running them easier,  \nlet's put them all in a function:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "def test_range_overlap():\n    assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None\n    assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None\n    assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)\n    assert range_overlap([ (2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)\n    assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)\n    assert range_overlap([]) == None", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "We can now test `range_overlap` with a single function call:  \n", "metadata": {}}, {"outputs": [], "cell_type": "code", "source": "test_range_overlap()", "metadata": {"scrolled": false, "format": "row", "collapsed": false}, "execution_count": 1}, {"attachments": {}, "cell_type": "markdown", "source": "---  \n```python\n---------------------------------------------------------------------------  \nAssertionError                            Traceback (most recent call last)  \n<ipython-input-29-cf9215c96457> in <module>()  \n----> 1 test_range_overlap()  \n\n<ipython-input-28-5d4cd6fd41d9> in test_range_overlap()  \n      1 def test_range_overlap():  \n----> 2     assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None  \n      3     assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None  \n      4     assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)  \n      5     assert range_overlap([ (2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)  \n\nAssertionError:  \n```\n---  \n{: .error}  \n\nThe first test that was supposed to produce `None` fails,  \nso we know something is wrong with our function.  \nWe *don't* know whether the other tests passed or failed  \nbecause Python halted the program as soon as it spotted the first error.  \nStill,  \nsome information is better than none,  \nand if we trace the behavior of the function with that input,  \nwe realize that we're initializing `max_left` and `min_right` to 0.0 and 1.0 respectively,  \nregardless of the input values.  \nThis violates another important rule of programming:  \n*always initialize from data*.  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "The first test that was supposed to produce `None` fails,  \nso we know something is wrong with our function.  \nWe *don't* know whether the other tests passed or failed  \nbecause Python halted the program as soon as it spotted the first error.  \nStill,  \nsome information is better than none,  \nand if we trace the behavior of the function with that input,  \nwe realize that we're initializing `max_left` and `min_right` to 0.0 and 1.0 respectively,  \nregardless of the input values.  \nThis violates another important rule of programming:  \n*always initialize from data*.  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "## Pre- and Post-Conditions  \n\nSuppose you are writing a function called `average` that calculates  \nthe average of the numbers in a list.  \nWhat pre-conditions and post-conditions would you write for it?  \nCompare your answer to your neighbor's:  \ncan you think of a function that will pass your tests but not his/hers or vice versa?  \n\n<details>  \n<summary><b> Solution</b></summary>  \n\n---  \n```python\n# a possible pre-condition:  \nassert len(input_list) > 0, 'List length must be non-zero'  \n# a possible post-condition:  \nassert numpy.min(input_list) <= average <= numpy.max(input_list),  \n'Average should be between min and max of input values (inclusive)'  \n```\n---  \n\n</details>  \n", "metadata": {}}, {"attachments": {}, "cell_type": "markdown", "source": "## Testing Assertions  \n\nGiven a sequence of a number of cars, the function `get_total_cars` returns  \nthe total number of cars.  \n\n---  \n```python\nget_total_cars([1, 2, 3, 4])  \n```\n---  \n\n\n---  \n```python\n10  \n```\n---  \n\n\n---  \n```python\nget_total_cars(['a', 'b', 'c'])  \n```\n---  \n\n\n---  \n```python\nValueError: invalid literal for int() with base 10: 'a'  \n```\n---  \n\n\nExplain in words what the assertions in this function check,  \nand for each one,  \ngive an example of input that will make that assertion fail.  \n\n---  \n```python\ndef get_total(values):  \nassert len(values) > 0  \nfor element in values:  \nassert int(element)  \nvalues = [int(element) for element in values]  \ntotal = sum(values)  \nassert total > 0  \nreturn total  \n```\n---  \n\n\n<details>  \n<summary><b> Solution</b></summary>  \n\n*   The first assertion checks that the input sequence `values` is not empty.  \nAn empty sequence such as `[]` will make it fail.  \n*   The second assertion checks that each value in the list can be turned into an integer.  \nInput such as `[1, 2,'c', 3]` will make it fail.  \n*   The third assertion checks that the total of the list is greater than 0.  \nInput such as `[-10, 2, 3]` will make it fail.  \n</details>  \n", "metadata": {}}], "nbformat": 4}